{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n"
     ]
    }
   ],
   "source": [
    "#Perform all the imports\n",
    "\n",
    "import spacy\n",
    "import pandas\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the text file\n",
    "\n",
    "fp = open('History-Class6.txt', 'r')\n",
    "text = fp.read()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing the text\n",
    "\n",
    "# 1. Removing punctuations\n",
    "text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "# 2. Convert to lower case\n",
    "text = text.lower()\n",
    "\n",
    "# 3. Remove tags\n",
    "text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "\n",
    "# 4. Remove special characters\n",
    "text = re.sub(\"(\\W)+\", \" \", text)\n",
    "\n",
    "# 5. Convert to list\n",
    "text = text.split()\n",
    "\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'to', 'they', 'be', 'the', 'were', 'some', 'by', 'that', 'in', 'of', 'people', 'as', 'was', 'a', 'had', 'who', 'these', 'this']\n",
      "['people']\n"
     ]
    }
   ],
   "source": [
    "#Extract common words / word-count\n",
    "\n",
    "#freq = pandas.Series(text.split()).value_counts()[:40]\n",
    "#freq\n",
    "\n",
    "word_c = {}                         #Create a dictionary to hold the frequencies of every word.\n",
    "for word in text:\n",
    "    if word in word_c.keys():\n",
    "        word_c[word] += 1\n",
    "    else:\n",
    "        word_c[word] = 1\n",
    "word_c\n",
    "\n",
    "#Choose mechanism to set threshold to decide stop words.\n",
    "# a. Divide the total number of words in the text by x\n",
    "# b. Divide the number of words in the dictionary by x\n",
    "#Chosen mechanism = percentile\n",
    "\n",
    "frequencies = [v for v in word_c.values()]\n",
    "threshold = np.percentile(frequencies, 97)\n",
    "\n",
    "#Creating custom stop words list.\n",
    "\n",
    "s_w = []\n",
    "for k, v in word_c.items():\n",
    "    if v>threshold:\n",
    "        s_w.append(k)\n",
    "print((s_w))\n",
    "\n",
    "#Adding custom stop words\n",
    "\n",
    "new_sw = []\n",
    "def custom_stop_words(word):\n",
    "    if not nlp.vocab[word].is_stop:\n",
    "        new_sw.append(word)                        #Just to keep a record of the custom words added.\n",
    "        nlp.Defaults.stop_words.add(word)\n",
    "        nlp.vocab[word].is_stop = True\n",
    "\n",
    "for word in s_w:\n",
    "    custom_stop_words(word)\n",
    "print(new_sw)    \n",
    "#print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "\n",
    "doc = nlp(\" \".join(text))\n",
    "lemmatized_list = []\n",
    "for token in doc:\n",
    "    lemmatized_list.append(token.lemma_)\n",
    "print(len(lemmatized_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words\n",
    "\n",
    "doc = nlp(\" \".join(lemmatized_list))\n",
    "filtered_list = []\n",
    "for token in doc:\n",
    "    if not token.is_stop:\n",
    "        if not token.is_punct:\n",
    "            if not token.text == '-PRON-':\n",
    "                filtered_list.append(token.text)\n",
    "print(len(filtered_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "cv=CountVectorizer(max_df=0.8,stop_words=nlp.Defaults.stop_words, max_features=10000, ngram_range=(1,3))\n",
    "X=cv.fit_transform(filtered_list)\n",
    "#list(cv.vocabulary_.keys())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most frequently occuring words\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      \n",
    "                   vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                       reverse=True)\n",
    "    return words_freq[:n]\n",
    "#Convert most freq words to dataframe for plotting bar plot\n",
    "top_words = get_top_n_words(filtered_list, n=20)\n",
    "top_df = pandas.DataFrame(top_words)\n",
    "top_df.columns=[\"Word\", \"Freq\"]\n",
    "#print(top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "# get feature names\n",
    "feature_names=cv.get_feature_names()\n",
    " \n",
    "# fetch document for which keywords needs to be extracted\n",
    "doc=\" \".join(filtered_list)\n",
    " \n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:\n",
      "kingdom king early republic election day shankaran wake grandparent ready vote want reach polling booth shankaran want know excited somewhat impatiently grandfather explain choose ruler today man ruler choose leader ruler voting common year man ruler past raja read chapter probably choose jana year ago find change place way rajas choose man recognise rajas perform big sacrifice ashvamedha horse sacrifice ritual horse let loose wander freely guard raja s man horse wander kingdom raja stop fight allow horse pass mean accept raja want perform sacrifice strong raja invite sacrifice perform specially train priest reward gift raja organise sacrifice recognise powerful come bring gift raja central figure ritual special seat throne tiger skin charioteer companion battle field witness exploit chant tale glory relative especially wife son perform variety minor ritual raja simply spectator sit watch performance sacrifice priest perform ritual include sprinkling sacred water king ordinary vish vaishya bring gift regard shudra priest exclude ritual list present sacrifice category describe term occupation varna book compose north india especially area drain ganga yamuna period book later vedic compose rigveda learn chapter include samaveda yajurveda atharvaveda book compose priest describe ritual perform contain rule society different group society time priest warrior farmer herder trader craft person labourer fish folk forest priest warrior rich farmer trader include herder craft person labourer fish folk hunter gatherer poor priest divide group varna accord varna different set function varna brahmin brahmin expect study teach veda perform sacrifice receive gift second place ruler know kshatriyas expect fight battle protect vish vaishya expect farmer herder trader kshatriyas vaishya perform sacrifice shudra serve group perform ritual woman group shudra woman shudra allow study veda priest group decide basis birth example s father mother brahmin automatically brahmin later classify untouchable include craft person hunter gatherer help perform burial cremation priest contact group pollute accept system varna lay brahmin king think superior priest feel birth basis decide varna belong feel difference base occupation feel everybody able perform ritual condemn practice untouchability area subcontinent north east social economic difference sharp influence priest limit oppose system varna ncert class vi social study chapter kingdom king early republic janapada raja perform big sacrifice recognise raja janapada jana word janapada literally mean land jana set foot settle important janapada map page ncert class vi social study chapter kingdom king early republic archaeologist excavate number settlement janapada purana qila delhi hastinapur near meerut atranjikhera near etah uttar pradesh find live hut cattle animal grow variety crop rice wheat barley pulse sugarcane sesame mustard crop list mention chapter earthen pot grey colour red special type pottery find site know paint grey ware obvious grey pot paint design usually simple line geometric pattern mahajanapada year ago janapada important know mahajanapada map mahajanapada capital city fortify mean huge wall wood brick stone build fort probably build afraid attack king need protection likely ruler want rich powerful build large tall impressive wall city way land live inside fortified area control easily king build huge wall require great deal plan thousand lakh brick stone prepare turn mean enormous labour provide possibly thousand man woman child resource find ncert class vi social study chapter kingdom king early republic new rajas begin maintain army soldier pay regular salary maintain king year payment probably use punch marked coin illustration page read coin chapter list way rajas mahajanapada different mention rigveda tax ruler mahajanapada build huge fort b maintain big army need resource need official collect instead depend occasional gift bring case raja janapada start collect regular tax tax crop important farmer usually tax fix th produce know bhaga share tax craft person form labour example weaver smith work day month king herder expect pay tax form animal animal produce tax good buy sell trade hunter gatherer provide forest produce raja think provide hunter gatherer change agriculture major change agriculture time grow use iron ploughshare mean heavy clayey soil turn better wooden ploughshare grain produce second begin transplant paddy mean instead scatter seed ground plant sprout sapling grow plant field lead increase production plant survive break work generally slave man woman dasa dasis landless agricultural labourer kammakara work think king encourage change close look magadha find magadha map page magadha important mahajanapada year river ganga son flow magadha important transport b water supply c land fertile magadha forest elephant live forest capture train army forest provide wood building house cart chariot iron ore region tap strong tool weapon magadha powerful ruler bimbisara ajatasattu use possible mean conquer janapada mahapadma nanda important ruler extend control north west subcontinent rajagriha present day rajgir bihar capital magadha year later capital shift pataliputra present day patna year ago ruler alexander live macedonia europe want world conqueror course didn t conquer world conquer egypt west asia come indian subcontinent reach bank bea want march eastward soldier refuse scar hear ruler india vast army foot soldier chariot elephant way army different describe rigveda close look b vajji magadha powerful kingdom vajji capital vaishali bihar different form government know gana sangha gana sangha ncert class vi social study chapter kingdom king early republic ruler thousand man rule know raja raja perform ritual meet assembly decide discussion debate example attack enemy meet discuss meet threat women dasa kammakara participate assembly buddha mahavira read chapter belong gana sanghas vivid description life sanghas find buddhist book ncert class vi social study chapter kingdom king early republicthis account vajjis digha nikaya famous buddhist book contain speech buddha write year ago ajatasattu vajjis ajatasattu want attack vajjis send minister vassakara buddha advice matter buddha ask vajjis meet frequently assembly hear reply vajjis continue prosper long hold frequent public assembly meet act follow establish rule respect support listen elder vajji woman hold force capture chaityas local shrine maintain town village wise saint follow different belief respect allow enter leave country freely way vajji sangha different mahajanapada try list difference rajas powerful kingdom try conquer sangha long time till year ago gana sangha conquer gupta ruler read chapter find greece athen atla year ago athen set form government democracy year free man age recognise citizen assembly meet time year decide important matter citizen attend meeting appointment position lottery want choose select lottery citizen expect serve army navy woman consider citizen foreigner live work athen merchant craft person right citizen thousand slave athen work field household workshop treat citizen think true democracy imagine peep crack wall assembly vaishali meeting progress discuss way deal attack king magadha describe hear\n",
      "\n",
      "Keywords:\n",
      "raja 0.184\n",
      "king 0.184\n",
      "ruler 0.173\n",
      "perform 0.173\n",
      "year 0.162\n",
      "priest 0.151\n",
      "chapter 0.151\n",
      "sacrifice 0.139\n",
      "ritual 0.127\n",
      "magadha 0.127\n"
     ]
    }
   ],
   "source": [
    "#Function for sorting tf_idf in descending order\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\nAbstract:\")\n",
    "print(doc)\n",
    "print(\"\\nKeywords:\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n"
     ]
    }
   ],
   "source": [
    "#Restoring the stop word list.\n",
    "\n",
    "def remove_stop_word(word):\n",
    "    if nlp.vocab[word].is_stop:\n",
    "        nlp.Defaults.stop_words.remove(word)\n",
    "        nlp.vocab[word].is_stop = False\n",
    "\n",
    "for word in new_sw:\n",
    "    remove_stop_word(word)\n",
    "\n",
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
